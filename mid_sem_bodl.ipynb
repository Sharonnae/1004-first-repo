{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharonnae/1004-first-repo/blob/master/mid_sem_bodl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mid-semester assignment Part 1 - Basics of deep learning\n",
        "Hello dear students,<br> this is the template notebook. Please upload it into your drive and open as Google Colab nootebook\".\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### Name and ID:\n",
        "Student 1:\n",
        "<br>\n",
        "Student 2:"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XDDbguyGU8Fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST\n",
        "Fashion MNIST dataset contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  \n",
        "</table>\n",
        "\n"
      ],
      "metadata": {
        "id": "JLkWLC8f3HZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "\n",
        "# Goodluck!"
      ],
      "metadata": {
        "id": "WiRxNFCn3Vxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network in plain NumPy"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4K84YZ_QU8Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "QReFpU112hLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tLOHjUiFU8Fv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "D5MsCpUv2tuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "nbzv9ZYA2pyW",
        "outputId": "c8b00eaa-9062-4480-fef3-fbb56abf30cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPBGGKtSoVpU"
      },
      "source": [
        "## Data preprocessing (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfq8otp-wXY"
      },
      "source": [
        "### Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MZtZIzzDIKe"
      },
      "source": [
        "examples = y.shape[0]\n",
        "y1 = y.reshape(1, examples)\n",
        "X1 = X / 255\n",
        "X1 = X1.T\n",
        "print(X1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6K01j7A_Z4W"
      },
      "source": [
        "### Select two classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuPZ0o8DNWq"
      },
      "source": [
        "#TODO: select two classes (for example 2-Pullover and 4-Coat)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn5UPcIQH2jS"
      },
      "source": [
        "### Split the data into Train set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBUI2DZmhd0y"
      },
      "source": [
        "# TODO: Split the data into Train set and Test set (The use of libraries other than Numpy is strictly prohibited)\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X = # YOUR CODE HERE\n",
        "Y = # YOUR CODE HERE\n",
        "\n",
        "# Use shuffle on the train data\n",
        "X, y = shuffle(X, Y)\n",
        "\n",
        "X_train, X_test = # YOUR CODE HERE\n",
        "Y_train, Y_test = # YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg7D7fwGH9Yv"
      },
      "source": [
        "### Test yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkLl0PSyDR9S"
      },
      "source": [
        "# Test yourself (Check that the classes you have selected are actually displayed)\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "i = random.randint(100)\n",
        "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_train[i,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81OW5M7oCWZ"
      },
      "source": [
        "## Activation functions (10%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxruxXBsDmP-"
      },
      "source": [
        "#TODO: Sigmoid activation function\n",
        "def sigmoid(z):\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIAUcVboOG9"
      },
      "source": [
        "## Loss function (20%)\n",
        "BCE Loss function captures the intuition that the neural network should pay a high penalty(Loss→∞) when the estimated probability, with respect to the training example’s label, is completely wrong. On the other hand, the Loss should equal zero(Loss=0) when the estimated probability, with respect to the training example’s label, is correct. Simply put, the BCE Loss should equal zero in only two instances:<br>\n",
        "* if the example is positively labeled(y=1) the neural network model should be completely sure that the example belongs to the positive class i.e p̂=1.\n",
        "* if the example is negatively labeled(y=0) the neural network model should be completely sure that the example does not belong to the positive class i.e p̂=0.\n",
        "\n",
        "<b> When we work with a computer, there are very high values or very low values that it cannot handle and that could cause the system to crash. <br>In order to overcome the case where the function returns values that strive for infinity you will need to understand which range of values causes the logarithm to return inf \\ -inf and handle this within the function. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0i2o9_KDUdQ"
      },
      "source": [
        "#TODO: Binary cross entropy\n",
        "def log_loss(y_hat, y):\n",
        "    '''\n",
        "    Logistic loss, assuming a single value in y_hat and y.\n",
        "    '''\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY9DQPrJmvHZ"
      },
      "source": [
        "## NN Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGCU_QYRnJap"
      },
      "source": [
        "input_layer = X_train.shape[0] # 28X28 = 784\n",
        "hidden_layer = # YOUR CODE HERE\n",
        "learning_rate = # YOUR CODE HERE\n",
        "epochs = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SdHpc2m3vV"
      },
      "source": [
        "## Weight and Bias Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVRoMGxTnLZI"
      },
      "source": [
        "W1 = np.random.randn(hidden_layer, input_layer)\n",
        "b1 = np.zeros((hidden_layer, 1))\n",
        "W2 = np.random.randn(1, hidden_layer)\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "print(W1.shape)\n",
        "print(b1.shape)\n",
        "print(W2.shape)\n",
        "print(b2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp-IaWECn6Hu"
      },
      "source": [
        "## Training (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdlcCGLDo7F"
      },
      "source": [
        "X = X_train\n",
        "Y = Y_train\n",
        "loss_list = []\n",
        "epoch_list = []\n",
        "numOfTraining = # Write the number of examples in your train set\n",
        "\n",
        "for i in range(epochs):\n",
        "  avg_epoch_loss = 0\n",
        "  for j in range(numOfTraining):\n",
        "    # TODO :  Forward propagation\n",
        "    \n",
        "    Z1 = np.matmul(W1,X[:,j]) # DO NOT FORGET TO ADD THE BIAS\n",
        "    A1 = # WRITE YOUR CODE HERE\n",
        "    Z2 = # WRITE YOUR CODE HERE\n",
        "    A2 = # WRITE YOUR CODE HERE\n",
        "    Yout = # WRITE YOUR CODE HERE\n",
        "\n",
        "    # TODO: Compute loss\n",
        "    loss = log_loss( A2, Yout)\n",
        "    avg_epoch_loss = avg_epoch_loss + loss\n",
        "\n",
        "    # # TODO: Back propagation\n",
        "    dZ2 = (A2-Yout)\n",
        "    dW2 = # WRITE YOUR CODE HERE\n",
        "    db2 = # WRITE YOUR CODE HERE\n",
        "\n",
        "    dA1 = # WRITE YOUR CODE HERE\n",
        "    dZ1 = # WRITE YOUR CODE HERE \n",
        "    dW1 = # WRITE YOUR CODE HERE\n",
        "    db1 = # WRITE YOUR CODE HERE\n",
        "\n",
        "    # TODO: Update weights\n",
        "    W2 = # WRITE YOUR CODE HERE\n",
        "    b2 = # WRITE YOUR CODE HERE\n",
        "    W1 = # WRITE YOUR CODE HERE\n",
        "    b1 = # WRITE YOUR CODE HERE\n",
        "\n",
        "  avg_epoch_loss = avg_epoch_loss/numOfTraining\n",
        "  loss_list.append(avg_epoch_loss)\n",
        "  epoch_list.append(i)\n",
        "  print(\"Epoch\", i,\" Loss:\", avg_epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdgCk97534-B"
      },
      "source": [
        "### Loss Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFo9NN5Q31X8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(epoch_list, loss_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "5HV5g7j92Xfn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raBFclM5ploH"
      },
      "source": [
        "### Test your performance (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flfh-luxDs7Z"
      },
      "source": [
        "#TODO: Forward batch of examples\n",
        "X = X_test\n",
        "Y = Y_test\n",
        "\n",
        "Z1 = np.matmul(W1, X_test) + b1\n",
        "A1 = # WRITE YOUR CODE HERE\n",
        "Z2 = # WRITE YOUR CODE HERE\n",
        "A2 = # WRITE YOUR CODE HERE\n",
        "\n",
        "\n",
        "predictions = np.zeros((1,Y.shape[0]))\n",
        "labels = np.zeros((1,Y.shape[0]))\n",
        "\n",
        "# Check your predictions against the test's labels\n",
        "for i in range(Y.shape[0]):\n",
        "  if (A2[0,i] > 0.5): \n",
        "    predictions[0,i] = 1\n",
        "  labels[0,i] = Y[i,0]\n",
        "\n",
        "\n",
        "# Print the confusion matrix In order to test your performance\n",
        "print(confusion_matrix(predictions.T, labels.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the results"
      ],
      "metadata": {
        "id": "7FtZr0EQBlcm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAj_5W2wVUrI"
      },
      "source": [
        "#TODO: SHOW VISUALLY RESULTS ON 10 TEST EXAMPLES\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "i = random.randint(2000)\n",
        "plt.imshow(X_test[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_test[i,0]\n",
        "\n",
        "Z1 = np.matmul(W1,X_test[:,i]) \n",
        "A1 = # WRITE YOUR CODE HERE\n",
        "Z2 = # WRITE YOUR CODE HERE\n",
        "A2 = # WRITE YOUR CODE HERE\n",
        "Yout = Y[i,0] \n",
        "print(\"Real=\", Y_test[i,0], \"Predicted=\",A2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}